{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQno0GefINs_"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF6e9JtynBAD",
        "outputId": "62b3c565-7d23-4978-8303-31caa48d5bbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.8.1\n",
            "  Downloading torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 804.1 MB 2.8 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (4.1.1)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.8.1 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.8.1 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.8.1 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyro-ppl==1.3.0\n",
            "  Downloading pyro_ppl-1.3.0-py3-none-any.whl (495 kB)\n",
            "\u001b[K     |████████████████████████████████| 495 kB 14.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.3.0) (1.21.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.3.0) (3.3.0)\n",
            "Collecting pyro-api>=0.1.1\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.3.0) (1.8.1)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.3.0) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->pyro-ppl==1.3.0) (4.1.1)\n",
            "Installing collected packages: pyro-api, pyro-ppl\n",
            "Successfully installed pyro-api-0.1.2 pyro-ppl-1.3.0\n"
          ]
        }
      ],
      "source": [
        "#@title Imports\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import copy\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from tqdm import tqdm\n",
        "from keras.utils import np_utils\n",
        "\n",
        "!pip install torch==1.8.1\n",
        "import torch\n",
        "torch.set_default_dtype(torch.float32)\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "import torch.nn.functional as nnf\n",
        "softplus = torch.nn.Softplus()\n",
        "import torch.optim as torchopt\n",
        "\n",
        "!pip install pyro-ppl==1.3.0\n",
        "import pyro\n",
        "from pyro import poutine\n",
        "import pyro.distributions as dist\n",
        "from pyro.optim import Adam\n",
        "import pyro.optim as pyroopt\n",
        "from pyro.nn import PyroModule\n",
        "from pyro.infer import SVI, Trace_ELBO, TraceMeanField_ELBO\n",
        "from pyro.distributions import Normal, Categorical, OneHotCategorical\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6Wz-aI5T9am",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4550dd1-3f84-4072-d427-d5fad09e523d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# set device \n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "APuRaywaHHTa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fd1779b-fe1f-43da-8b1a-207c21ca15c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #importing the dataset\n",
        "dataset = pd.read_csv('/content/drive/My Drive/smart_grid_stability_augmented.csv')"
      ],
      "metadata": {
        "id": "G20QDYMUHMHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.replace({'stabf': {'unstable':0, 'stable':1}}, inplace=True)"
      ],
      "metadata": {
        "id": "pAXtZ73nHPDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.drop(columns=['stab'])"
      ],
      "metadata": {
        "id": "j7dpHuxJHRL5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "16678dc2-fefb-47a9-a1a2-e7f242875369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
              "0      2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
              "1      9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
              "2      8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
              "3      0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
              "4      3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "59995  2.930406  2.376523  9.487627  6.187797  3.343416 -1.449106 -0.658054   \n",
              "59996  3.392299  2.954947  1.274827  6.894759  4.349512 -0.952437 -1.663661   \n",
              "59997  2.364034  8.776391  2.842030  1.008906  4.299976 -0.943884 -1.380719   \n",
              "59998  9.631511  2.757071  3.994398  7.821347  2.514755 -0.649915 -0.966330   \n",
              "59999  6.530527  4.349695  6.781790  8.673138  3.492807 -1.532193 -1.390285   \n",
              "\n",
              "             p4        g1        g2        g3        g4  stabf  \n",
              "0     -1.723086  0.650456  0.859578  0.887445  0.958034      0  \n",
              "1     -1.255012  0.413441  0.862414  0.562139  0.781760      1  \n",
              "2     -0.920492  0.163041  0.766689  0.839444  0.109853      0  \n",
              "3     -0.997374  0.446209  0.976744  0.929381  0.362718      0  \n",
              "4     -0.554305  0.797110  0.455450  0.656947  0.820923      0  \n",
              "...         ...       ...       ...       ...       ...    ...  \n",
              "59995 -1.236256  0.601709  0.813512  0.779642  0.608385      0  \n",
              "59996 -1.733414  0.502079  0.285880  0.567242  0.366120      1  \n",
              "59997 -1.975373  0.487838  0.149286  0.986505  0.145984      1  \n",
              "59998 -0.898510  0.365246  0.889118  0.587558  0.818391      0  \n",
              "59999 -0.570329  0.073056  0.378761  0.505441  0.942631      0  \n",
              "\n",
              "[60000 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88ef94a9-b3dd-4e5a-a54b-d15bc5056ef1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tau1</th>\n",
              "      <th>tau2</th>\n",
              "      <th>tau3</th>\n",
              "      <th>tau4</th>\n",
              "      <th>p1</th>\n",
              "      <th>p2</th>\n",
              "      <th>p3</th>\n",
              "      <th>p4</th>\n",
              "      <th>g1</th>\n",
              "      <th>g2</th>\n",
              "      <th>g3</th>\n",
              "      <th>g4</th>\n",
              "      <th>stabf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.959060</td>\n",
              "      <td>3.079885</td>\n",
              "      <td>8.381025</td>\n",
              "      <td>9.780754</td>\n",
              "      <td>3.763085</td>\n",
              "      <td>-0.782604</td>\n",
              "      <td>-1.257395</td>\n",
              "      <td>-1.723086</td>\n",
              "      <td>0.650456</td>\n",
              "      <td>0.859578</td>\n",
              "      <td>0.887445</td>\n",
              "      <td>0.958034</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.304097</td>\n",
              "      <td>4.902524</td>\n",
              "      <td>3.047541</td>\n",
              "      <td>1.369357</td>\n",
              "      <td>5.067812</td>\n",
              "      <td>-1.940058</td>\n",
              "      <td>-1.872742</td>\n",
              "      <td>-1.255012</td>\n",
              "      <td>0.413441</td>\n",
              "      <td>0.862414</td>\n",
              "      <td>0.562139</td>\n",
              "      <td>0.781760</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.971707</td>\n",
              "      <td>8.848428</td>\n",
              "      <td>3.046479</td>\n",
              "      <td>1.214518</td>\n",
              "      <td>3.405158</td>\n",
              "      <td>-1.207456</td>\n",
              "      <td>-1.277210</td>\n",
              "      <td>-0.920492</td>\n",
              "      <td>0.163041</td>\n",
              "      <td>0.766689</td>\n",
              "      <td>0.839444</td>\n",
              "      <td>0.109853</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.716415</td>\n",
              "      <td>7.669600</td>\n",
              "      <td>4.486641</td>\n",
              "      <td>2.340563</td>\n",
              "      <td>3.963791</td>\n",
              "      <td>-1.027473</td>\n",
              "      <td>-1.938944</td>\n",
              "      <td>-0.997374</td>\n",
              "      <td>0.446209</td>\n",
              "      <td>0.976744</td>\n",
              "      <td>0.929381</td>\n",
              "      <td>0.362718</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.134112</td>\n",
              "      <td>7.608772</td>\n",
              "      <td>4.943759</td>\n",
              "      <td>9.857573</td>\n",
              "      <td>3.525811</td>\n",
              "      <td>-1.125531</td>\n",
              "      <td>-1.845975</td>\n",
              "      <td>-0.554305</td>\n",
              "      <td>0.797110</td>\n",
              "      <td>0.455450</td>\n",
              "      <td>0.656947</td>\n",
              "      <td>0.820923</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>2.930406</td>\n",
              "      <td>2.376523</td>\n",
              "      <td>9.487627</td>\n",
              "      <td>6.187797</td>\n",
              "      <td>3.343416</td>\n",
              "      <td>-1.449106</td>\n",
              "      <td>-0.658054</td>\n",
              "      <td>-1.236256</td>\n",
              "      <td>0.601709</td>\n",
              "      <td>0.813512</td>\n",
              "      <td>0.779642</td>\n",
              "      <td>0.608385</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>3.392299</td>\n",
              "      <td>2.954947</td>\n",
              "      <td>1.274827</td>\n",
              "      <td>6.894759</td>\n",
              "      <td>4.349512</td>\n",
              "      <td>-0.952437</td>\n",
              "      <td>-1.663661</td>\n",
              "      <td>-1.733414</td>\n",
              "      <td>0.502079</td>\n",
              "      <td>0.285880</td>\n",
              "      <td>0.567242</td>\n",
              "      <td>0.366120</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>2.364034</td>\n",
              "      <td>8.776391</td>\n",
              "      <td>2.842030</td>\n",
              "      <td>1.008906</td>\n",
              "      <td>4.299976</td>\n",
              "      <td>-0.943884</td>\n",
              "      <td>-1.380719</td>\n",
              "      <td>-1.975373</td>\n",
              "      <td>0.487838</td>\n",
              "      <td>0.149286</td>\n",
              "      <td>0.986505</td>\n",
              "      <td>0.145984</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>9.631511</td>\n",
              "      <td>2.757071</td>\n",
              "      <td>3.994398</td>\n",
              "      <td>7.821347</td>\n",
              "      <td>2.514755</td>\n",
              "      <td>-0.649915</td>\n",
              "      <td>-0.966330</td>\n",
              "      <td>-0.898510</td>\n",
              "      <td>0.365246</td>\n",
              "      <td>0.889118</td>\n",
              "      <td>0.587558</td>\n",
              "      <td>0.818391</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>6.530527</td>\n",
              "      <td>4.349695</td>\n",
              "      <td>6.781790</td>\n",
              "      <td>8.673138</td>\n",
              "      <td>3.492807</td>\n",
              "      <td>-1.532193</td>\n",
              "      <td>-1.390285</td>\n",
              "      <td>-0.570329</td>\n",
              "      <td>0.073056</td>\n",
              "      <td>0.378761</td>\n",
              "      <td>0.505441</td>\n",
              "      <td>0.942631</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88ef94a9-b3dd-4e5a-a54b-d15bc5056ef1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88ef94a9-b3dd-4e5a-a54b-d15bc5056ef1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88ef94a9-b3dd-4e5a-a54b-d15bc5056ef1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = torch.tensor(dataset[\"stabf\"].values, dtype=torch.float)"
      ],
      "metadata": {
        "id": "TFEf158yHTPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into inputs and outputs\n",
        "df = dataset.iloc[:, :12]"
      ],
      "metadata": {
        "id": "q8GLIuvYHYAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset normalization\n",
        "df = (df-df.min())/(df.max()-df.min())"
      ],
      "metadata": {
        "id": "oAfY8rmZHZ5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch tensor of features\n",
        "features = torch.stack([torch.tensor(df[colname].values, dtype=torch.float) for colname in df], dim=1)\n",
        "\n",
        "# train-test split\n",
        "k = int(0.8 * len(dataset))\n",
        "x_train, y_train = features[:k], labels[:k]\n",
        "x_test, y_test = features[k:], labels[k:]\n",
        "\n",
        "print(\"x_train.shape =\", x_train.shape,\"\\ny_train.shape =\", y_train.shape)\n",
        "print(\"\\nx_test.shape =\", x_test.shape,\"\\ny_test.shape =\", y_test.shape)"
      ],
      "metadata": {
        "id": "YjzUtGblHcLp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "108aad98-ed3d-4e24-a3a6-ad737a19f1ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape = torch.Size([48000, 12]) \n",
            "y_train.shape = torch.Size([48000])\n",
            "\n",
            "x_test.shape = torch.Size([12000, 12]) \n",
            "y_test.shape = torch.Size([12000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpqNSHzGfwuk",
        "outputId": "263d808f-d75e-4a15-c605-72bfefd6887f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=2"
      ],
      "metadata": {
        "id": "51nVgzu9f21t"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHXvUDETUHVo"
      },
      "source": [
        "### Deterministic Neural Network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "hZbkjbzsvU4S"
      },
      "outputs": [],
      "source": [
        "class DeterministicNetwork(nn.Module):\n",
        "  \n",
        "    def __init__(self):\n",
        "\n",
        "        # initialize nn.Module\n",
        "        super(DeterministicNetwork, self).__init__()\n",
        "\n",
        "    \n",
        "        # architecture\n",
        "        self.model = nn.Sequential(\n",
        "                    nn.Linear(12, 100),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(100, 2))\n",
        "    \n",
        "        self.name = \"deterministic_network\"\n",
        "      \n",
        "\n",
        "    def forward(self, inputs, *args, **kwargs):\n",
        "        \"\"\" Compute predictions on `inputs`. \"\"\"\n",
        "        return self.model(inputs)\n",
        "\n",
        "    def train(self, x_train, y_train, lr, epochs, device):\n",
        "        \"\"\" Train network. \"\"\"\n",
        "        random.seed(0)\n",
        "\n",
        "        # DataLoader combines a dataset and a sampler, and provides an \n",
        "        # iterable over the given dataset\n",
        "        train_loader = DataLoader(dataset=list(zip(x_train, y_train)), \n",
        "                                  batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        # send network to device\n",
        "        self.to(device)\n",
        "\n",
        "        # set optimizer and loss function for training\n",
        "        optimizer = torchopt.Adam(params=self.parameters(), lr=lr)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "      \n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "\n",
        "            for x_batch, y_batch in train_loader:\n",
        "\n",
        "                # send data to device\n",
        "                x_batch = x_batch.to(device)\n",
        "                y_batch = y_batch.to(device)\n",
        "                \n",
        "\n",
        "                ### loss optimization ###\n",
        "                outputs = self.forward(x_batch) # forward pass\n",
        "              \n",
        "\n",
        "                # reset gradients w.r.t. network parameters\n",
        "                optimizer.zero_grad() \n",
        "\n",
        "                # loss on predicted labels vs true labels\n",
        "                loss = loss_fn(outputs, y_batch.long()) \n",
        "                \n",
        "\n",
        "                # backward pass: computes the derivative of the loss w.r.t.\n",
        "                # the parameters using backpropagation.\n",
        "                loss.backward() \n",
        "\n",
        "                # update parameters, i.e. take a step based on the gradients \n",
        "                # of the parameters.\n",
        "                optimizer.step() \n",
        "                #########################\n",
        "\n",
        "                # update training loss\n",
        "                total_loss += loss.data.item() / len(train_loader.dataset)\n",
        "        \n",
        "            print(f\"\\n[Epoch {epoch + 1}]\\t loss: {total_loss:.8f}\", end=\"\\t\")\n",
        "\n",
        "    def save(self, savedir):\n",
        "        \"\"\" Save network weights. \"\"\"\n",
        "        self.to(\"cpu\") # send network to cpu\n",
        "        os.makedirs(savedir, exist_ok=True)\n",
        "        torch.save(self.state_dict(), os.path.join(savedir, self.name+\"_weights.pt\"))\n",
        "      \n",
        "    def load(self, savedir, device):\n",
        "        \"\"\" Load network weights. \"\"\"\n",
        "        self.load_state_dict(torch.load(os.path.join(savedir, self.name+\"_weights.pt\")))\n",
        "        self.to(device)\n",
        "      \n",
        "    def evaluate(self, x_test, y_test, device, *args, **kwargs):\n",
        "        \"\"\" Evaluate network on test set. \"\"\"\n",
        "        random.seed(0)\n",
        "        self.to(device)\n",
        "\n",
        "        test_loader = DataLoader(dataset=list(zip(x_test, y_test)), batch_size=batch_size, shuffle=False)       \n",
        "\n",
        "        # disable gradients computation\n",
        "        with torch.no_grad():\n",
        "\n",
        "            correct_predictions = 0\n",
        "\n",
        "            # compute predictions on mini-batch\n",
        "            for x_batch, y_batch in test_loader:\n",
        "                x_batch = x_batch.to(device)\n",
        "                y_batch = y_batch.to(device).argmax(-1)\n",
        "                outputs = self(x_batch) # self.forward(x_batch)\n",
        "                predictions = outputs.argmax(dim=-1)\n",
        "                correct_predictions += (predictions == y_batch).sum()\n",
        "\n",
        "            accuracy = 100 * correct_predictions / len(test_loader.dataset)\n",
        "\n",
        "        return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "f7IpvNvxUPDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "812cd8d9-65fb-4414-ed38-1c33c6d7e56d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Epoch 1]\t loss: 0.13685297\t\n",
            "[Epoch 2]\t loss: 0.11567681\t\n",
            "[Epoch 3]\t loss: 0.11627966\t\n",
            "[Epoch 4]\t loss: 0.11356674\t\n",
            "[Epoch 5]\t loss: 0.11038052\t\n",
            "Test accuracy: 62.53%\n"
          ]
        }
      ],
      "source": [
        "det_model = DeterministicNetwork()\n",
        "det_model.train(x_train=x_train, y_train=y_train, lr=0.05, epochs=5, device=device)\n",
        "\n",
        "accuracy = det_model.evaluate(x_test, y_test, device=device)\n",
        "print(\"\\nTest accuracy: %.2f%%\" % (accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EERqqBN2sZNP"
      },
      "source": [
        "### Bayesian Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "O1ZiGB7Nszr-"
      },
      "outputs": [],
      "source": [
        "class BayesianNetwork(PyroModule):\n",
        "\n",
        "    def __init__(self):\n",
        "        # initialize PyroModule\n",
        "        super(BayesianNetwork, self).__init__()\n",
        "\n",
        "        # BayesianNetwork extends PyroModule class\n",
        "        self.det_network = DeterministicNetwork()\n",
        "\n",
        "        self.name = \"bayesian_network\"\n",
        "      \n",
        "    def model(self, x_data, y_data):\n",
        "        \"\"\" Sets prior distributions and conditions on the observations. \"\"\"\n",
        "        priors = {}\n",
        "    \n",
        "        # set Gaussian priors on the weights of self.det_network\n",
        "        for key, value in self.det_network.state_dict().items():\n",
        "            loc = torch.zeros_like(value)\n",
        "            scale = torch.ones_like(value)\n",
        "            prior = Normal(loc=loc, scale=scale)\n",
        "            priors.update({str(key):prior})\n",
        "\n",
        "        # pyro.random_module places `priors` over the parameters of the nn.Module \n",
        "        # self.det_network and returns a distribution, which upon calling \n",
        "        # samples a new nn.Module (`lifted_module`)\n",
        "        lifted_module = pyro.random_module(\"module\", self.det_network, priors)()\n",
        "\n",
        "        # samples are conditionally independent w.r.t. the observed data\n",
        "        with pyro.plate(\"data\", len(x_data)):\n",
        "            out = lifted_module(x_data) # out.shape = (batch_size, num_classes)\n",
        "            obs = pyro.sample(\"obs\", Categorical(logits=out), obs=y_data) # obs.shape = (batch_size)\n",
        "\n",
        "    def guide(self, x_data, y_data=None):\n",
        "        \"\"\" Samples from the Variational distribution and returns predictions. \"\"\"\n",
        "\n",
        "        # take random samples of det_network's weights from the chosen variational family\n",
        "        dists = {}\n",
        "        for key, value in self.det_network.state_dict().items():\n",
        "\n",
        "            # torch.randn_like(x) builds a random tensor whose shape equals x.shape\n",
        "            loc = pyro.param(str(f\"{key}_loc\"), torch.randn_like(value)) \n",
        "            scale = pyro.param(str(f\"{key}_scale\"), torch.randn_like(value))\n",
        "\n",
        "            # softplus is a smooth approximation to the ReLU function\n",
        "            # which constraints the scale tensor to positive values\n",
        "            distr = Normal(loc=loc, scale=softplus(scale))\n",
        "\n",
        "            # add key-value pair to the samples dictionary\n",
        "            dists.update({str(key):distr})\n",
        "\n",
        "        # define a random module from the dictionary of distributions\n",
        "        lifted_module = pyro.random_module(\"module\", self.det_network, dists)()\n",
        "\n",
        "        with pyro.plate(\"data\", len(x_data)):\n",
        "\n",
        "            # compute predictions on `x_data`\n",
        "            out = lifted_module(x_data)\n",
        "            preds = nnf.softmax(out, dim=-1)\n",
        "            return preds\n",
        "        \n",
        "    def forward(self, inputs, n_samples=10, sample_idx=None, avg_prediction=True):\n",
        "        \"\"\" Compute predictions on `inputs`. \n",
        "        `n_samples` is the number of samples from the posterior distribution.\n",
        "        If `sample_idx` is provided, it is used as a seed for sampling a single\n",
        "        model from the Variational family.\n",
        "        If `avg_prediction` is True, it returns the average prediction on \n",
        "        `inputs`, otherwise it returns all predictions \n",
        "        \"\"\"\n",
        "        if sample_idx:\n",
        "            # set random seeds for both torch and pyro\n",
        "            random.seed(sample_idx)\n",
        "            pyro.set_rng_seed(sample_idx)    \n",
        "\n",
        "            # sample from the guide() function and evaluate it on `inputs`        \n",
        "            guide_trace = poutine.trace(self.guide).get_trace(inputs)  \n",
        "\n",
        "            # get the output prediction from the guide() function\n",
        "            preds = [guide_trace.nodes['_RETURN']['value']]\n",
        "        \n",
        "        else:\n",
        "            preds = []\n",
        "            # take multiple samples\n",
        "            for _ in range(n_samples):         \n",
        "                guide_trace = poutine.trace(self.guide).get_trace(inputs)  \n",
        "                preds.append(guide_trace.nodes['_RETURN']['value'])\n",
        "        \n",
        "        # list of tensors to tensor\n",
        "        # preds.shape = (n_samples, batch_size, n_classes)\n",
        "        preds = torch.stack(preds)\n",
        "\n",
        "        # return predictions \n",
        "        return preds.mean(0) if avg_prediction else preds\n",
        "\n",
        "    def train(self, x_train, y_train, lr, epochs, device):\n",
        "        \"\"\" Learn network's weights using SVI. \"\"\"\n",
        "        random.seed(0)\n",
        "        pyro.set_rng_seed(0)\n",
        "        pyro.clear_param_store()\n",
        "\n",
        "        train_loader = DataLoader(dataset=list(zip(x_train, y_train)), \n",
        "                                  batch_size=batch_size, shuffle=False)\n",
        " \n",
        "        # send bayesian network and deterministic network to device\n",
        "        self.to(device)\n",
        "        self.det_network.to(device)\n",
        "\n",
        "        # ELBO loss minimization\n",
        "        optimizer = pyro.optim.Adam({\"lr\":lr})\n",
        "        elbo = TraceMeanField_ELBO()\n",
        "        svi = SVI(self.model, self.guide, optimizer, loss=elbo)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            loss = 0.0\n",
        "\n",
        "            for x_batch, y_batch in train_loader:\n",
        "\n",
        "                x_batch = x_batch.to(device)\n",
        "                y_batch = y_batch.to(device).argmax(-1)\n",
        "                loss += svi.step(x_data=x_batch, y_data=y_batch)\n",
        "\n",
        "            total_loss = loss / len(train_loader.dataset)\n",
        "            print(f\"Epoch {epoch + 1}]\\t loss: {total_loss:.2f}\")\n",
        "          \n",
        "    def save(self, savedir):\n",
        "        \"\"\" Save posterior weights. \"\"\"\n",
        "        os.makedirs(savedir, exist_ok=True)\n",
        "        fullpath = os.path.join(savedir, self.name+\"_weights.pt\")\n",
        "        param_store = pyro.get_param_store()\n",
        "        param_store.save(fullpath)\n",
        "        \n",
        "    def load(self, savedir, device):\n",
        "        \"\"\" Load posterior weights. \"\"\"\n",
        "        fullpath = os.path.join(savedir, self.name+\"_weights.pt\")\n",
        "        param_store = pyro.get_param_store()\n",
        "        param_store.load(os.path.join(savedir, fullpath))\n",
        "        for key, value in param_store.items():\n",
        "            param_store.replace_param(key, value.to(device), value)\n",
        "\n",
        "    def evaluate(self, x_test, y_test, device, n_samples=10, avg_prediction=True):\n",
        "        \"\"\" Evaluate network on test set. \"\"\"\n",
        "        random.seed(0)\n",
        "        pyro.set_rng_seed(0)  \n",
        "\n",
        "        test_loader = DataLoader(dataset=list(zip(x_test, y_test)), \n",
        "                                 batch_size=batch_size, shuffle=False)\n",
        "        \n",
        "        self.to(device)\n",
        "        self.det_network.to(device)\n",
        "\n",
        "        # disable gradients computation\n",
        "        with torch.no_grad():\n",
        "\n",
        "            correct_predictions = 0.0\n",
        "\n",
        "            # compute predictions on mini-batch\n",
        "            for x_batch, y_batch in test_loader:\n",
        "\n",
        "                x_batch = x_batch.to(device)\n",
        "                y_batch = y_batch.to(device).argmax(-1)\n",
        "\n",
        "                outputs = self.forward(x_batch, n_samples=n_samples, avg_prediction=avg_prediction)\n",
        "                predictions = outputs.to(device).argmax(-1)\n",
        "                correct_predictions += (predictions == y_batch).sum().item()\n",
        "\n",
        "            accuracy = 100 * correct_predictions / len(test_loader.dataset)\n",
        "        \n",
        "        return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "2ixPir2kr8sS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f55f573c-edc8-4f1c-877e-12a5ff09823e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1]\t loss: 5.31\n",
            "Epoch 2]\t loss: 3.42\n",
            "Epoch 3]\t loss: 3.41\n",
            "Epoch 4]\t loss: 3.40\n",
            "Epoch 5]\t loss: 3.40\n",
            "\n",
            "Test accuracy: 76.16%\n"
          ]
        }
      ],
      "source": [
        "bay_model = BayesianNetwork()\n",
        "bay_model.train(x_train=x_train, y_train=y_train, lr=0.01, epochs=5, device=device)\n",
        "\n",
        "accuracy = bay_model.evaluate(x_test, y_test, device=device, n_samples=10)\n",
        "print(\"\\nTest accuracy: %.2f%%\" % (accuracy))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "BNN-detailed.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}